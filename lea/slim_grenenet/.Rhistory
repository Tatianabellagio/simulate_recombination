screeplot(RDA_env, main="Eigenvalues of constrained axes")
#anova(RDA.result)
screeplot(RDA.result, main="Eigenvalues of constrained axes")
#### Function to conduct a RDA based genome scan
rdadapt <- function(rda,K)
{
zscores<-rda$CCA$v[,1:as.numeric(K)]
resscale <- apply(zscores, 2, scale)
resmaha <- covRob(resscale, distance = TRUE, na.action= na.omit, estim="pairwiseGK")$dist
lambda <- median(resmaha)/qchisq(0.5,df=K)
reschi2test <- pchisq(resmaha/lambda,K,lower.tail=FALSE)
qval <- qvalue(reschi2test)
q.values_rdadapt<-qval$qvalues
return(data.frame(p.values=reschi2test, q.values=q.values_rdadapt))
}
## Running the function with K = 2
rdadapt_env<-rdadapt(RDA.result, 2)
install.packages("robust")
library(robust)
## Running the function with K = 2
rdadapt_env<-rdadapt(RDA.result, 2)
install.packages("qvalue")
#useful
#getwd()
#install.packages("vegan")
BiocManager::install("qvalue")
## Running the function with K = 2
rdadapt_env<-rdadapt(RDA.result, 2)
library(qvalue)
## Running the function with K = 2
rdadapt_env<-rdadapt(RDA.result, 2)
## P-values threshold after Bonferroni correction
thres_env <- 0.01/length(rdadapt_env$p.values)
## Identifying the loci that are below the p-value threshold
outliers <- data.frame(Loci = colnames(AllFreq)[which(rdadapt_env$p.values<thres_env)], p.value = rdadapt_env$p.values[which(rdadapt_env$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(AllFreq)[which(rdadapt_env$p.values<thres_env)], split = "_"), function(x) x[1])))
## Identifying the loci that are below the p-value threshold
outliers <- data.frame(Loci = colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], p.value = rdadapt_env$p.values[which(rdadapt_env$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(AllFreq)[which(rdadapt_env$p.values<thres_env)], split = "_"), function(x) x[1])))
## Identifying the loci that are below the p-value threshold
outliers <- data.frame(Loci = colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], p.value = rdadapt_env$p.values[which(rdadapt_env$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], split = "_"), function(x) x[1])))
## Top hit outlier per contig
outliers <- outliers[order(outliers$contig, outliers$p.value),]
## List of outlier names
outliers_rdadapt_env <- as.character(outliers$Loci[!duplicated(outliers$contig)])
## Formatting table for ggplot
locus_scores <- scores(RDA_env, choices=c(1:2), display="species", scaling="none") # vegan references "species", here these are the loci
## Formatting table for ggplot
locus_scores <- scores(RDA.result , choices=c(1:2), display="species", scaling="none") # vegan references "species", here these are the loci
TAB_loci <- data.frame(names = row.names(locus_scores), locus_scores)
TAB_loci$type <- "Neutral"
TAB_loci$type[TAB_loci$names%in%outliers$Loci] <- "All outliers"
TAB_loci$type[TAB_loci$names%in%outliers_rdadapt_env] <- "Top outliers"
TAB_loci$type <- factor(TAB_loci$type, levels = c("Neutral", "All outliers", "Top outliers"))
TAB_loci <- TAB_loci[order(TAB_loci$type),]
TAB_var <- as.data.frame(scores(RDA_env, choices=c(1,2), display="bp")) # pull the biplot scores
## Biplot of RDA loci and variables scores
ggplot() +
geom_hline(yintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_vline(xintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_point(data = TAB_loci, aes(x=RDA1*20, y=RDA2*20, colour = type), size = 1.4) +
scale_color_manual(values = c("gray90", "#F9A242FF", "#6B4596FF")) +
geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), colour="black", size=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5, family = "Times") +
xlab("RDA 1") + ylab("RDA 2") +
facet_wrap(~"RDA space") +
guides(color=guide_legend(title="Locus type")) +
theme_bw(base_size = 11, base_family = "Times") +
theme(panel.background = element_blank(), legend.background = element_blank(), panel.grid = element_blank(), plot.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
TAB_var <- as.data.frame(scores(RDA.result, choices=c(1,2), display="bp")) # pull the biplot scores
## Biplot of RDA loci and variables scores
ggplot() +
geom_hline(yintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_vline(xintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_point(data = TAB_loci, aes(x=RDA1*20, y=RDA2*20, colour = type), size = 1.4) +
scale_color_manual(values = c("gray90", "#F9A242FF", "#6B4596FF")) +
geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), colour="black", size=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5, family = "Times") +
xlab("RDA 1") + ylab("RDA 2") +
facet_wrap(~"RDA space") +
guides(color=guide_legend(title="Locus type")) +
theme_bw(base_size = 11, base_family = "Times") +
theme(panel.background = element_blank(), legend.background = element_blank(), panel.grid = element_blank(), plot.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
## Biplot of RDA loci and variables scores
ggplot() +
#  geom_hline(yintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
#  geom_vline(xintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_point(data = TAB_loci, aes(x=RDA1*20, y=RDA2*20, colour = type), size = 1.4) +
scale_color_manual(values = c("gray90", "#F9A242FF", "#6B4596FF")) +
geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), colour="black", size=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5, family = "Times") +
xlab("RDA 1") + ylab("RDA 2") +
facet_wrap(~"RDA space") +
guides(color=guide_legend(title="Locus type")) +
theme_bw(base_size = 11, base_family = "Times") +
theme(panel.background = element_blank(), legend.background = element_blank(), panel.grid = element_blank(), plot.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
# Manhattan plot
Outliers <- rep("Neutral", length(colnames(meanaf_2019)))
Outliers[colnames(meanaf_2019)%in%outliers$Loci] <- "All outliers"
Outliers[colnames(meanaf_2019)%in%outliers_rdadapt_env] <- "Top outliers"
Outliers <- factor(Outliers, levels = c("Neutral", "All outliers", "Top outliers"))
TAB_manhatan <- data.frame(pos = 1:length(colnames(meanaf_2019)),
pvalues = rdadapt_env$p.values,
Outliers = Outliers)
TAB_manhatan <- TAB_manhatan[order(TAB_manhatan$Outliers),]
ggplot(data = TAB_manhatan) +
geom_point(aes(x=pos, y=-log10(pvalues), col = Outliers), size=1.4) +
scale_color_manual(values = c("gray90", "#F9A242FF", "#6B4596FF")) +
xlab("Loci") + ylab("-log10(p.values)") +
geom_hline(yintercept=-log10(thres_env), linetype="dashed", color = gray(.80), size=0.6) +
facet_wrap(~"Manhattan plot", nrow = 3) +
guides(color=guide_legend(title="Locus type")) +
theme_bw(base_size = 11, base_family = "Times") +
theme(legend.position="right", legend.background = element_blank(), panel.grid = element_blank(), legend.box.background = element_blank(), plot.background = element_blank(), panel.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
#also only 2019
delta_freq_nonsyn_mean = fread("Documents/grenephase1/scratch_tati/delta_freq_nonsyn_mean.csv")
library(qvalue)
library(robust)
library(data.table)
library(vegan)
library(ggplot2)
library(ggvegan)
#also only 2019
delta_freq_nonsyn_mean = fread("Documents/grenephase1/scratch_tati/delta_freq_nonsyn_mean.csv")
## because there is only data for some sites first we are gonna filter the weather station data
sites_available = delta_freq_nonsyn_mean$site
worldclim_sitesdata = worldclim_sitesdata[worldclim_sitesdata$site %in% sites_available,]
View(delta_freq_nonsyn_mean)
RDA.result <- rda(meanaf_2019~bio1+bio12+bio5 ,data=worldclim_sitesdata)
summary(RDA.result)
RsquareAdj(RDA.result)
plot(RDA.result, display=c('sites','sp','lc', 'cn'))
## allele freq data
AF284 = readRDS('safedata/meixilin/grenenet/data/AF/ver202209/haplotype/AF284_0922.rds')
View(AF284)
AF284 <- cbind(position = rownames(AF284), AF284)
rownames(AF284) <- 1:nrow(AF284)
head(AF284)
fwrite(AF284, "Documents/grenephase1/scratch_tati/AF284.csv")
meanaf_2019_ns = fread("Documents/grenephase1/scratch_tati/final_af_2019_ns.csv")
## because there is only data for some sites first we are gonna filter the weather station data
sites_available = meanaf_2019_ns$site
worldclim_sitesdata = worldclim_sitesdata[worldclim_sitesdata$site %in% sites_available,]
View(meanaf_2019_ns)
head(meanaf_2019_ns)
View(meanaf_2019_ns)
## remove the site column
meanaf_2019_ns = within(meanaf_2019_ns, rm(V1))
RDA.result <- rda(meanaf_2019_ns~bio1+bio12+bio5 ,data=worldclim_sitesdata)
summary(RDA.result)
RsquareAdj(RDA.result)
vif.cca(RDA.result)
## VARIABLE SELECTION
## Null model
RDA0 <- rda(meanaf_2019_ns ~ 1,  worldclim_sitesdata)
## Full model
RDAfull <- rda(meanaf_2019_ns ~ bio1+bio2+bio3+bio4+bio5+bio6+bio7+bio8+bio9+bio10+bio11+bio12+bio13+bio14+bio15+bio16+bio17+bio18+bio19, worldclim_sitesdata)
## Stepwise procedure with ordiR2step function
mod <- ordiR2step(RDA0, RDAfull, Pin = 0.01, R2permutations = 1000, R2scope = T)
#bio1+bio2+bio3+bio4+bio5+bio6+bio7+bio8+bio9+bio10+bio11+bio12+bio13+bio14+bio15+bio16+bio17+bio18+bio19
## Full model
RDAfull <- rda(meanaf_2019_ns ~ bio4+bio16+bio17+bio9+bio14+bio19+bio6+bio3+bio10+bio15+bio1+bio18+bio8, worldclim_sitesdata)
## Stepwise procedure with ordiR2step function
mod <- ordiR2step(RDA0, RDAfull, Pin = 0.01, R2permutations = 1000, R2scope = T)
## with selected variables
RDA.result <- rda(meanaf_2019~ + bio3 + bio16  + bio1  + bio15 + bio12  ,data=worldclim_sitesdata)
#anova(RDA.result)
screeplot(RDA.result, main="Eigenvalues of constrained axes")
#### Function to conduct a RDA based genome scan
rdadapt <- function(rda,K)
{
zscores<-rda$CCA$v[,1:as.numeric(K)]
resscale <- apply(zscores, 2, scale)
resmaha <- covRob(resscale, distance = TRUE, na.action= na.omit, estim="pairwiseGK")$dist
lambda <- median(resmaha)/qchisq(0.5,df=K)
reschi2test <- pchisq(resmaha/lambda,K,lower.tail=FALSE)
qval <- qvalue(reschi2test)
q.values_rdadapt<-qval$qvalues
return(data.frame(p.values=reschi2test, q.values=q.values_rdadapt))
}
## Running the function with K = 2
rdadapt_env<-rdadapt(RDA.result, 2)
## P-values threshold after Bonferroni correction
thres_env <- 0.01/length(rdadapt_env$p.values)
## Identifying the loci that are below the p-value threshold
outliers <- data.frame(Loci = colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], p.value = rdadapt_env$p.values[which(rdadapt_env$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], split = "_"), function(x) x[1])))
## Top hit outlier per contig
outliers <- outliers[order(outliers$contig, outliers$p.value),]
## List of outlier names
outliers_rdadapt_env <- as.character(outliers$Loci[!duplicated(outliers$contig)])
## Formatting table for ggplot
locus_scores <- scores(RDA.result , choices=c(1:2), display="species", scaling="none") # vegan references "species", here these are the loci
TAB_loci <- data.frame(names = row.names(locus_scores), locus_scores)
TAB_loci$type <- "Neutral"
TAB_loci$type[TAB_loci$names%in%outliers$Loci] <- "All outliers"
TAB_loci$type[TAB_loci$names%in%outliers_rdadapt_env] <- "Top outliers"
TAB_loci$type <- factor(TAB_loci$type, levels = c("Neutral", "All outliers", "Top outliers"))
TAB_loci <- TAB_loci[order(TAB_loci$type),]
TAB_var <- as.data.frame(scores(RDA.result, choices=c(1,2), display="bp")) # pull the biplot scores
## Biplot of RDA loci and variables scores
ggplot() +
#  geom_hline(yintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
#  geom_vline(xintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_point(data = TAB_loci, aes(x=RDA1*20, y=RDA2*20, colour = type), size = 1.4) +
scale_color_manual(values = c("gray90", "#F9A242FF", "#6B4596FF")) +
geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), colour="black", size=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5, family = "Times") +
xlab("RDA 1") + ylab("RDA 2") +
facet_wrap(~"RDA space") +
guides(color=guide_legend(title="Locus type")) +
theme_bw(base_size = 11, base_family = "Times") +
theme(panel.background = element_blank(), legend.background = element_blank(), panel.grid = element_blank(), plot.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
outliers
## Running the function with K = 2
rdadapt_env<-rdadapt(RDA.result, 3)
## P-values threshold after Bonferroni correction
thres_env <- 0.01/length(rdadapt_env$p.values)
## Identifying the loci that are below the p-value threshold
outliers <- data.frame(Loci = colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], p.value = rdadapt_env$p.values[which(rdadapt_env$p.values<thres_env)], contig = unlist(lapply(strsplit(colnames(meanaf_2019)[which(rdadapt_env$p.values<thres_env)], split = "_"), function(x) x[1])))
## Top hit outlier per contig
outliers <- outliers[order(outliers$contig, outliers$p.value),]
outliers
## List of outlier names
outliers_rdadapt_env <- as.character(outliers$Loci[!duplicated(outliers$contig)])
## Formatting table for ggplot
locus_scores <- scores(RDA.result , choices=c(1:2), display="species", scaling="none") # vegan references "species", here these are the loci
TAB_loci <- data.frame(names = row.names(locus_scores), locus_scores)
TAB_loci$type <- "Neutral"
TAB_loci$type[TAB_loci$names%in%outliers$Loci] <- "All outliers"
TAB_loci$type[TAB_loci$names%in%outliers_rdadapt_env] <- "Top outliers"
TAB_loci$type <- factor(TAB_loci$type, levels = c("Neutral", "All outliers", "Top outliers"))
TAB_loci <- TAB_loci[order(TAB_loci$type),]
TAB_var <- as.data.frame(scores(RDA.result, choices=c(1,2), display="bp")) # pull the biplot scores
## Biplot of RDA loci and variables scores
ggplot() +
#  geom_hline(yintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
#  geom_vline(xintercept=0, linetype="dashed", color = gray(.80), size=0.6) +
geom_point(data = TAB_loci, aes(x=RDA1*20, y=RDA2*20, colour = type), size = 1.4) +
scale_color_manual(values = c("gray90", "#F9A242FF", "#6B4596FF")) +
geom_segment(data = TAB_var, aes(xend=RDA1, yend=RDA2, x=0, y=0), colour="black", size=0.15, linetype=1, arrow=arrow(length = unit(0.02, "npc"))) +
geom_text(data = TAB_var, aes(x=1.1*RDA1, y=1.1*RDA2, label = row.names(TAB_var)), size = 2.5, family = "Times") +
xlab("RDA 1") + ylab("RDA 2") +
facet_wrap(~"RDA space") +
guides(color=guide_legend(title="Locus type")) +
theme_bw(base_size = 11, base_family = "Times") +
theme(panel.background = element_blank(), legend.background = element_blank(), panel.grid = element_blank(), plot.background = element_blank(), legend.text=element_text(size=rel(.8)), strip.text = element_text(size=11))
options(
repos = c(
zkamvar = "https://zkamvar.r-universe.dev",
CRAN = "https://cloud.r-project.org"
)
)
install.packages("adegenet")
library("adegenet")
data <- read.csv("allele_counts.csv", header=FALSE)
setwd("/Users/tbellagio/Documents/grenephase1/scratch_tati/simulations/lea/slim_grenenet/")
data <- read.csv("allele_counts.csv", header=FALSE)
pop <- genind2genpop(data)
data(nancycats)
View(nancycats)
data(microbov)
View(microbov)
X <- tab(microbov, freq = TRUE, NA.method = "mean")
X
View(X)
dim(X)
data(microbov)
X <- tab(microbov, NA.method = "mean")
data <- read.csv("allele_counts.csv", header=FALSE)
data <- read.csv("allele_freq.csv", header=FALSE)
pca1 <- dudi.pca(data, scale = FALSE, scannf = FALSE, nf = 3)
barplot(pca1$eig[1:50], main = "PCA eigenvalues", col = heat.colors(50))
pca1
s.label(pca1$li)
title("PCA") add.scatter.eig(pca1$eig[1:20], 3,1,2)
title("PCA")
add.scatter.eig(pca1$eig[1:20], 3,1,2)
pca1$eig
barplot(pca1$eig[1:16], main = "PCA eigenvalues", col = heat.colors(50))
pca1 <- dudi.pca(data, scale = FALSE, scannf = FALSE, nf = 3)
barplot(pca1$eig[1:16], main = "PCA eigenvalues", col = heat.colors(50))
s.label(pca1$li)
title("PCA")
add.scatter.eig(pca1$eig[1:16], 3,1,2)
add.scatter.eig(pca1$eig[1:16], 1,1,1)
pca1$eig[1:16]
pca1$eig[1:15]
add.scatter.eig(pca1$eig[1:15], 3,1,2)
barplot(pca1$eig[1:15], main = "PCA eigenvalues", col = heat.colors(50))
pca1$eig
s.label(pca1$li)
title("PCA")
add.scatter.eig(pca1$eig[1:15], 3,1,2)
pop(microbov)
len(pop(microbov))
pop(microbov).length()
length(pop(microbov))
dim(X)
s.class(pca1$li)
barplot(pca1$eig[1:15], main = "PCA eigenvalues", col = heat.colors(50))
barplot(pca1$eig[1:15], main = "PCA eigenvalues", col = heat.colors(15))
pca1$eig
pca1
s.label(pca1$li)
title("PCA")
add.scatter.eig(pca1$eig[1:3], 3,1,2)
data <- read.csv("allele_freq.csv", header=FALSE)
env = read.csv("env.env", header=FALSE)
mod.lfmm2 <- lfmm2(input = data, env = env, K = 3)
#Simulate non-null effect sizes for 10 target loci #individuals
n = 100
#loci
L = 1000
# Environmental variable
X = as.matrix(rnorm(n))
# effect sizes
B = rep(0, L)
target = sample(1:L, 10)
# GEA significance test
# showing the K = 2 estimated factors
plot(mod.lfmm2@U, col = "grey", pch = 19, xlab = "Factor 1",
ylab = "Factor 2")
mod.lfmm2 <- lfmm2(input = data, env = env, K = 3)
library(LEA)
mod.lfmm2 <- lfmm2(input = data, env = env, K = 3)
#Simulate non-null effect sizes for 10 target loci #individuals
n = 100
#loci
L = 1000
# Environmental variable
X = as.matrix(rnorm(n))
# effect sizes
B = rep(0, L)
target = sample(1:L, 10)
# GEA significance test
# showing the K = 2 estimated factors
plot(mod.lfmm2@U, col = "grey", pch = 19, xlab = "Factor 1",
ylab = "Factor 2")
B[target] = runif(10, -10, 10)
#Create 3 hidden factors and their loadings
U = t(tcrossprod(as.matrix(c(-1,0.5,1.5)), X)) + matrix(rnorm(3*n), ncol = 3)
V <- matrix(rnorm(3*L), ncol = 3)
pv <- lfmm2.test(object = mod.lfmm2,
input = data,
env = env,
full = TRUE)
plot(-log10(pv$pvalues), col = 'grey', cex = .5, pch = 19)
abline(h = -log10(0.1/16), lty = 2, col = "orange")
write.csv(-log10(pv$pvalues), "log10p_values_snps")
n = 500 # individuals
n = 500 # individuals
p = 5000 # SNPs for both null and alternative
f = 0.5 # MAF
b.alt = 0.2 # effect size under the alternative hypothesis
x = rbinom(n, 2, f) # genotypes at 1 SNP for n ind
x
x.hist()
hist(x)
y = scale( rnorm(n) ) # random phenotype normalized to have sample sd=1
y
hist(y)
summary( lm( y ~ x )
summary( lm( y ~ x ) )
se = summary( lm( y ~ x ) )$coeff[2,2] # pick SE, and assume it stays constant and independent of beta
summary( lm( y ~ x ) )
plot(x = x, y = y)
abline(fit, col = "red")
fit =lm( y ~ x )
plot(x = x, y = y)
abline(fit, col = "red")
summary( lm( y ~ x ) )$coeff
summary( lm( y ~ x ) )$coeff[2,2]
b.hat.null = rnorm(p, 0, se) # estimates under null
b.hat.null
hist(b.hat.null)
b.hat.alt = rnorm(p, b.alt, se)  # estimates under alternative
hist(b.hat.alt)
par(mfrow=c(1,2))
# Plot observed densities of z-scores
plot(NULL, xlim = c(-3,6), ylim = c(0,0.5), xlab = "z",
ylab = "density", col = "white") # empty panel for plotting
lines(density( (b.hat.null/se) ), col = "black", lwd = 2) # Wald statistic for null variants
lines(density( (b.hat.alt/se) ), col = "red", lwd = 2) # Wald statistic for alternative variants
# add theoretical densities for z-scores
x.seq = seq(-3, 6, 0.01)
lines(x.seq, dnorm(x.seq, 0, 1), col = "blue", lty = 2) # for null
lines(x.seq, dnorm(x.seq, b.alt/se, 1), col = "orange", lty = 2) # for alternative
# Plot observed densities of z^2
plot(NULL, xlim = c(0,35), ylim = c(0,1), xlab = expression(z^2),
ylab = "density", col = "white") # empty panel for plotting
lines(density( (b.hat.null/se)^2 ), col = "black", lwd = 2) # chi-square stat for null variants
lines(density( (b.hat.alt/se)^2 ), col = "red", lwd = 2) # chi-square stat for alternative variants
# Let's add theoretical densities of the chi-square distributions
x.seq = seq(0, 35, 0.01)
lines(x.seq, dchisq(x.seq, df = 1, ncp = 0), col = "blue", lty = 2) # ncp=0 for null
lines(x.seq, dchisq(x.seq, df = 1, ncp = (b.alt/se)^2), col = "orange", lty = 2) # ncp = (beta/se)^2 for alternative
legend("topright", leg = c("NULL obs'd","ALT obs'd","NULL theor","ALT theor"),
col = c("black","red","blue","orange"),
lty = c(1,1,2,2), lwd = c(2,2,1,1) )
# Let's add significance thresholds corresponding to 0.05 and 5e-8
# By definition, the thresholds are always computed under the null.
q.thresh = qchisq( c(0.05, 5e-8), df = 1, ncp = 0, lower = FALSE)
abline(v = q.thresh, col = c("darkgreen", "springgreen"), lty = 3)
text( q.thresh+2, c(0.4,0.4), c("P<0.05","P<5e-8") )
n = 500 # individuals
p = 5000 # SNPs for both null and alternative
f = 0.5 # MAF
b.alt = 0.2 # effect size under the alternative hypothesis
## simulate genotypes at 1 snp for n individuals
# n independent trials, 2 possible outcomes, maf probability of sucess
x = rbinom(n, 2, f) # genotypes at 1 SNP for n ind
## simulate random phenotype
rnorm(n)
## simulate random phenotype
y = rnorm(n)
hist(y)
y = scale( rnorm(n) ) # random phenotype normalized to have sample sd=1
hist(y)
# regressing y in x
summary( lm( y ~ x ) )
fit =lm( y ~ x )
plot(x = x, y = y)
abline(fit, col = "red")
summary( lm( y ~ x ) )$coeff
se = summary( lm( y ~ x ) )$coeff[2,2] # pick SE, and assume it stays constant and independent of beta
se
# simulate the 2 betas
b.hat.null = rnorm(p, 0, se) # estimates under null
hist(b.hat.null)
## beta under alt hipo
b.hat.alt = rnorm(p, b.alt, se)  # estimates under alternative
hist(b.hat.alt)
# add theoretical densities for z-scores
x.seq = seq(-3, 6, 0.01)
x.seq
# Plot observed densities of z-scores
plot(NULL, xlim = c(-3,6), ylim = c(0,0.5), xlab = "z",
ylab = "density", col = "white") # empty panel for plotting
## the walt stats is basically the beta/se
lines(density( (b.hat.null/se) ), col = "black", lwd = 2) # Wald statistic for null variants
lines(density( (b.hat.alt/se) ), col = "red", lwd = 2) # Wald statistic for alternative variants
# add theoretical densities for z-scores
x.seq = seq(-3, 6, 0.01)
lines(x.seq, dnorm(x.seq, 0, 1), col = "blue", lty = 2) # for null
lines(x.seq, dnorm(x.seq, b.alt/se, 1), col = "orange", lty = 2) # for alternative
q.thresh = qchisq(c(0.05,5e-8), df = 1, ncp = 0, lower = FALSE) # signif. thresholds in chi-square units
pchisq(q.thresh, df = 1, ncp = (b.alt/se)^2, lower = FALSE) # corresponding right tail probabilities
q.thresh
hist(b.hat.null)
hist(b.hat.alt)
## minor allele freq
f = 0.5
## beta under alt hypothesis
b.alt = 0.2
sigma = sqrt(1 - 2*f*(1-f)*b.alt^2) # error sd after SNP effect is accounted for (see next part for explanation)
ns = seq(500, 4000, 10) # candidate values for n
ses = sigma/sqrt(ns*2*f*(1-f)) # SEs corresponding to each candidate n
q.thresh = qchisq(5e-8, df = 1, ncp = 0, lower = F) # chi-sqr threshold corresponding to alpha = 5e-8
pwr = pchisq(q.thresh, df = 1, ncp=(b.alt/ses)^2, lower=F) # power at alpha = 5e-8 for VECTOR of SE values
plot(ns, pwr, col = "darkgreen", xlab = "n", ylab = "power",
main = paste0("QT sd=1; MAF=",f,"; beta=",b.alt), t = "l", lwd = 1.5)
abline(h = 0.9, lty = 2)
## beta under alt hypothesis
b.alt = 2
sigma = sqrt(1 - 2*f*(1-f)*b.alt^2) # error sd after SNP effect is accounted for (see next part for explanation)
ns = seq(500, 4000, 10) # candidate values for n
ses = sigma/sqrt(ns*2*f*(1-f)) # SEs corresponding to each candidate n
q.thresh = qchisq(5e-8, df = 1, ncp = 0, lower = F) # chi-sqr threshold corresponding to alpha = 5e-8
pwr = pchisq(q.thresh, df = 1, ncp=(b.alt/ses)^2, lower=F) # power at alpha = 5e-8 for VECTOR of SE values
plot(ns, pwr, col = "darkgreen", xlab = "n", ylab = "power",
main = paste0("QT sd=1; MAF=",f,"; beta=",b.alt), t = "l", lwd = 1.5)
abline(h = 0.9, lty = 2)
## beta under alt hypothesis
b.alt = 0.9
sigma = sqrt(1 - 2*f*(1-f)*b.alt^2) # error sd after SNP effect is accounted for (see next part for explanation)
ns = seq(500, 4000, 10) # candidate values for n
ses = sigma/sqrt(ns*2*f*(1-f)) # SEs corresponding to each candidate n
q.thresh = qchisq(5e-8, df = 1, ncp = 0, lower = F) # chi-sqr threshold corresponding to alpha = 5e-8
pwr = pchisq(q.thresh, df = 1, ncp=(b.alt/ses)^2, lower=F) # power at alpha = 5e-8 for VECTOR of SE values
plot(ns, pwr, col = "darkgreen", xlab = "n", ylab = "power",
main = paste0("QT sd=1; MAF=",f,"; beta=",b.alt), t = "l", lwd = 1.5)
abline(h = 0.9, lty = 2)
## beta under alt hypothesis
b.alt = 0.5
sigma = sqrt(1 - 2*f*(1-f)*b.alt^2) # error sd after SNP effect is accounted for (see next part for explanation)
ns = seq(500, 4000, 10) # candidate values for n
ses = sigma/sqrt(ns*2*f*(1-f)) # SEs corresponding to each candidate n
q.thresh = qchisq(5e-8, df = 1, ncp = 0, lower = F) # chi-sqr threshold corresponding to alpha = 5e-8
pwr = pchisq(q.thresh, df = 1, ncp=(b.alt/ses)^2, lower=F) # power at alpha = 5e-8 for VECTOR of SE values
plot(ns, pwr, col = "darkgreen", xlab = "n", ylab = "power",
main = paste0("QT sd=1; MAF=",f,"; beta=",b.alt), t = "l", lwd = 1.5)
abline(h = 0.9, lty = 2)
## minor allele freq
f = 0.5
## beta under alt hypothesis
b.alt = 0.5
# candidate values for n
ns = seq(10, 4000, 10)
sigma = sqrt(1 - 2*f*(1-f)*b.alt^2) # error sd after SNP effect is accounted for (see next part for explanation)
ses = sigma/sqrt(ns*2*f*(1-f)) # SEs corresponding to each candidate n
q.thresh = qchisq(5e-8, df = 1, ncp = 0, lower = F) # chi-sqr threshold corresponding to alpha = 5e-8
pwr = pchisq(q.thresh, df = 1, ncp=(b.alt/ses)^2, lower=F) # power at alpha = 5e-8 for VECTOR of SE values
plot(ns, pwr, col = "darkgreen", xlab = "n", ylab = "power",
main = paste0("QT sd=1; MAF=",f,"; beta=",b.alt), t = "l", lwd = 1.5)
abline(h = 0.9, lty = 2)
# candidate values for n
ns = seq(10, 1000, 10)
sigma = sqrt(1 - 2*f*(1-f)*b.alt^2) # error sd after SNP effect is accounted for (see next part for explanation)
ses = sigma/sqrt(ns*2*f*(1-f)) # SEs corresponding to each candidate n
q.thresh = qchisq(5e-8, df = 1, ncp = 0, lower = F) # chi-sqr threshold corresponding to alpha = 5e-8
pwr = pchisq(q.thresh, df = 1, ncp=(b.alt/ses)^2, lower=F) # power at alpha = 5e-8 for VECTOR of SE values
plot(ns, pwr, col = "darkgreen", xlab = "n", ylab = "power",
main = paste0("QT sd=1; MAF=",f,"; beta=",b.alt), t = "l", lwd = 1.5)
abline(h = 0.9, lty = 2)
